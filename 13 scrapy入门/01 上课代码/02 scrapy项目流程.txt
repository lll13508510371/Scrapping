01 创建项目
    # 1.创建一个爬虫项目
    scrapy startproject +(项目名字<独一无二>)

    # 2.cd 切换到爬虫项目目录

    # 3.创建爬虫文件
    scrapy genspider (+爬虫文件的名字<独一无二的>) (+域名限制)

02 爬虫文件

    # 1. 修改数据起始地址
    # 2. 写解析数据的业务逻辑

03 爬虫逻辑的编写
    001
        在 settings.py 文件中关闭robots协议
    002
        在爬虫文件下修改起始网址
        在 parse 方法下面解析数据
    003
        在 items.py 文件中定义数据结构
    004
        在 pipelines.py 文件中写保存数据的逻辑
    005
        在 settings.py 配置文件中打开管道配置

04 执行项目
    scrapy crawl +(爬虫文件名字)